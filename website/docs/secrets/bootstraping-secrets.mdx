---
title: Bootstrapping Secrets
hide_title: true
---

# Overview

When accessing to protected resources there is a need for a client to authenticate before
the access is granted and the resource is consumed. For the authentication, a client presents
credentials that are either created manually or available through infrastructure a common scenario
is a secrets store.

Weave gitops allows you to provision the secret management infrastructure as part of [its capabilities](./setup-secrets-operator.mdx).
However, in order to provision the secret infrastructure, as any other application that has secrets, we
need to make the secret it needs to install it.

This type of initial secret is what we call it bootstrapping secret and this guide gives you
with the different alternatives that weave gitops gives you to achieve the task.

Bootstrapping secrets will be not only present while provision your secrets managmenet solution but in
any platform provisioning task that comes before you have avaialble before the secrets management solution
is availabe. Another common example is provisioning platform capabilities itself via
https://docs.gitops.weave.works/docs/cluster-management/getting-started/#profiles-and-clusters
that are stored in private repositories. For example https://fluxcd.io/flux/guides/helmreleases/#helm-repository-authentication-with-credentials

To address this problem, weave gitops provides the following alternatives:

- SecretSync CRD: to leverage weave gitops for secrets bootstrapping.
- SecretSync Terraform Module: to leverage terraform and t for secrets bootstrapping.

## Using `SecretSync` Custom Resource

`SecretSync` is a [Kubernetes Customer Resource](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)
that provides semantics to sync [Kuberentes Secrets](https://kubernetes.io/docs/concepts/configuration/secret/) from management cluster to leaf clusters.

An example could be seen below:

```yaml
apiVersion: capi.weave.works/v1alpha1
kind: SecretSync
metadata:
  name: my-dev-secret-syncer
  namespace: default
spec:
  clusterSelector:
    matchLabels:
      environment: dev
  secretRef:
    name: my-dev-secret
  targetNamespace: my-namespace
```
Where you could find two main configuration sections:

1) Select the secret to sync:

```yaml
  secretRef:
    name: my-dev-secret
```

2) Select the [GitopsClusters](https://docs.gitops.weave.works/docs/cluster-management/managing-existing-clusters/)
,that the secret will be synced to, via labels:

```yaml
  clusterSelector:
    matchLabels:
      environment: dev
```

More info about the CRD spec [here](./spec/v1alpha1/secretSync.mdx)

### Working with SecretSync

#### Before start

1. You are using [Weave Gitops Enterprise version > XX](https://docs.gitops.weave.works/docs/releases/) with support for SecretsSync.
2. You have a secret that you want to sync from the management cluster.
3. You have a set of GitopsClusters that you want to sync to.

#### Syncing secrets via SecretSync

1. Create SecretSync manifests using the secret for example

```yaml
apiVersion: capi.weave.works/v1alpha1
kind: SecretSync
metadata:
  name: my-dev-secret-syncer
  namespace: default
spec:
  clusterSelector:
    matchLabels:
      environment: dev
  secretRef:
    name: my-dev-secret
  targetNamespace: my-namespace
```

2. Check-in to your configuration repo within your management cluster

3. Create a PR, review and merge

4. See the progress

CLI

UI

5. See the secret created in your leaf cluster

CLI

UI

## Using Terraform and `TF-controller`

You could use terraform and tf-controller to provision the secrets. This scenario would be more suitable for an
organisation that already leverages terraform for cluster management infrastructure and want to created integrated workflows.

### Before start

- You have [TF-controller installed](../../terraform/get-started) in your management cluster
- You have some bootstrap secrets in the management cluster.
- You have a leaf cluster that you want to bootstrap secrets to.
- TF-controller has permissions to execute against the leaf cluster.

For example, in the context of [eks](../../terraform/aws-eks.mdx) you could leverage IRSA

```yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: tf-controller
  namespace: flux-system
spec:
...
  values:
    ...
    runner:
      serviceAccount:
        annotations:
          eks.amazonaws.com/role-arn: "arn:aws:iam::894516026745:role/leaf-tf-controller" # TODO: replace with your role
```

//TODO limit the role

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tf-runner
roleRef:
  kind: ClusterRole
  name: tf-runner
  apiGroup: rbac.authorization.k8s.io
subjects:
  - kind: ServiceAccount
    name: tf-runner
    namespace: flux-system
```

### Bootstrap secrets

//TODO how to distribute the module currently lives in wge
//probably just documentation at this stage
Check in your configuration repo Create a PR pointing to your terraform module for syncing secrets.


Adjust the configurationf your leaf cluster

Create the PR, review and merge

Once merged, see via tf-controller UI how the secrests has been created.


**Note (To be fixed)**

- you may have the following error

```bash
│ The "for_each" map includes keys derived from resource attributes that cannot be determined until apply, and so Terraform cannot determine the full set of keys that will
│ identify the instances of this resource.
│
│ When working with unknown values in for_each, it's better to define the map keys statically in your configuration and place apply-time results only in the map values.
│
│ Alternatively, you could use the -target planning option to first apply only the resources that the for_each value depends on, and then apply a second time to fully converge.
╵
```

- This is because the flux-system have to be applied before flux installation

Temp fix using

```bash
➜  flux git:(add-flux) ✗ tf apply -var "github_token=$GITHUB_TOKEN" --target=kubernetes_namespace.flux_system                                                          <aws:sts>
kubernetes_namespace.flux_system: Refreshing state... [id=wge2205-leaf-flux-system]

No changes. Your infrastructure matches the configuration.
```

Then the job should be fixed